{
 "metadata": {
  "name": "",
  "signature": "sha256:b3dda2c90a4b5e68bf93bab88b23b68fc30c864f2efc1af19757d3a155a99395"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "# The multinomial Naive Bayes classifier is for classification with discrete\n",
      "#    features (e.g. word counts for text classification).  The multinominal\n",
      "#    distribution normally requires integer feature counts.  However, fractional\n",
      "#    counts such as tf-idf may also work."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chats = pd.read_csv(\n",
      "    #r'/Users/williamliu/Dropbox/GA/OriginalData/chatsegments_small.csv'\n",
      "    r'/Users/williamliu/Desktop/chatsegments_smallclean.csv'\n",
      "    #,dtype={'ChatStartTime': np.datetime64, 'ChatEndTime': np.datetime64 }\n",
      "    #, parse_dates=True\n",
      "    )\n",
      "\n",
      "chats['ChatStartTime'] = pd.to_datetime(chats['ChatStartTime'])\n",
      "chats['ChatEndTime'] = pd.to_datetime(chats['ChatEndTime'])\n",
      "chats['TimeSpent'] = chats['ChatEndTime'] - chats['ChatStartTime']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chats.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 6610 entries, 0 to 6609\n",
        "Data columns (total 21 columns):\n",
        "AcctID                6610 non-null int64\n",
        "CallQID               6610 non-null int64\n",
        "SessionID             6610 non-null int64\n",
        "AcctName              6610 non-null object\n",
        "CallQName             6610 non-null object\n",
        "ChatID                6610 non-null int64\n",
        "ChatStartTime         6610 non-null datetime64[ns]\n",
        "ChatEndTime           6610 non-null datetime64[ns]\n",
        "TimeDiffSec           6610 non-null float64\n",
        "ChatName              6610 non-null object\n",
        "HasVisitorSegments    6610 non-null int64\n",
        "ChatAccepted          6610 non-null int64\n",
        "ChatWaitTime          6610 non-null int64\n",
        "OperatorID            6610 non-null int64\n",
        "OperatorName          6610 non-null object\n",
        "SegmentID             6610 non-null int64\n",
        "SegmentType           6610 non-null int64\n",
        "SegmentText           6610 non-null object\n",
        "SegTime               6600 non-null object\n",
        "suicidal              6610 non-null int64\n",
        "TimeSpent             6610 non-null timedelta64[ns]\n",
        "dtypes: datetime64[ns](2), float64(1), int64(11), object(6), timedelta64[ns](1)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print chats.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'AcctID', u'CallQID', u'SessionID', u'AcctName', u'CallQName', u'ChatID', u'ChatStartTime', u'ChatEndTime', u'TimeDiffSec', u'ChatName', u'HasVisitorSegments', u'ChatAccepted', u'ChatWaitTime', u'OperatorID', u'OperatorName', u'SegmentID', u'SegmentType', u'SegmentText', u'SegTime', u'suicidal', u'TimeSpent'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit_transform will learn the vocabulary of our chats and extracts the\n",
      "# word count features; in return we get a 'word' and a 'count' as our features\n",
      "count_vectorizer = CountVectorizer()\n",
      "counts = count_vectorizer.fit_transform(np.asarray(chats['SegmentText'].str.decode('iso-8859-1').str.encode('utf-8')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Next step is to train a classifier and classify individual chats\n",
      "# using Naive Bayes Classifier (meaning Naive Independence Assumptions)\n",
      "# Each word count is independent from one another and contributes the same\n",
      "\n",
      "# Temporary for now until actual scores are entered\n",
      "\n",
      "classifier = MultinomialNB()\n",
      "targets = np.asarray(chats['suicidal'])\n",
      "classifier.fit(counts, targets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 122,
       "text": [
        "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test out our trained suicidal classifier\n",
      "examples = [\"This is some random test\", \"Hello how are you doing?\"]\n",
      "example_counts = count_vectorizer.transform(examples)\n",
      "predictions = classifier.predict(example_counts)\n",
      "predictions # Our predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 125,
       "text": [
        "array([1, 1])"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
      "    #TO-DO Add tdidf_transformer\n",
      "    ('classifier', MultinomialNB()) ])\n",
      "pipeline.fit(np.asarray(chats['SegmentText'].str.decode('iso-8859-1').str.encode('utf-8')),\n",
      "             np.asarray(chats['suicidal']))\n",
      "pipeline.predict(examples)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 144,
       "text": [
        "array([1, 1])"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Doing Cross-Validation\n",
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "k_fold = KFold(n=len(chats), n_folds=6, indices=False)\n",
      "scores = []\n",
      "for train_indices, test_indices in k_fold:\n",
      "    train_text = np.asarray(chats[train_indices]['SegmentText'].str.decode('iso-8859-1').str.encode('utf-8'))\n",
      "    train_y = np.asarray(chats[train_indices]['suicidal'])\n",
      "    \n",
      "    test_text = np.asarray(chats[test_indices]['SegmentText'].str.decode('iso-8859-1').str.encode('utf-8'))\n",
      "    test_y = np.asarray(chats[test_indices]['suicidal'])\n",
      "    score = pipeline.score(test_text, test_y)\n",
      "    scores.append(score)\n",
      "\n",
      "score = sum(scores) / len(scores)\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.876245842612\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#X = np.random.randint(5, size=(6, 20))\n",
      "#print \"X is \\n\", X\n",
      "#y = np.array([1, 2, 3, 4, 5, 6])\n",
      "#print \"y is \\n\", y\n",
      "\n",
      "# Setup Classifier and Vectorizer\n",
      "clf = MultinomialNB() # classifier for Naive Bayes multinomial models\n",
      "#vectorizer =TfidfVectorizer\n",
      "clf.fit(X, y)\n",
      "print clf.fit(X, y) # Fit the Naive Bayes classifier according to X, y\n",
      "print(clf.predict(X[2])) # Predict Probability estimates for test vector X\n",
      "print \"Score is \", clf.score(X, y) # Mean accuracy on the given test data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X is \n",
        "[[4 2 4 4 0 1 4 2 2 3 2 1 2 1 3 2 3 0 3 3]\n",
        " [0 4 0 4 1 4 1 3 0 3 2 4 3 4 0 1 1 2 1 1]\n",
        " [0 0 0 2 0 4 4 0 3 0 4 4 4 4 0 2 4 3 0 2]\n",
        " [3 3 1 4 3 3 3 0 0 2 4 4 0 2 2 0 4 3 4 4]\n",
        " [3 2 1 2 3 3 1 1 4 2 1 4 0 4 3 1 0 0 4 1]\n",
        " [1 2 4 0 1 4 3 2 0 3 4 0 3 2 1 2 4 0 4 4]]\n",
        "y is \n",
        "[1 2 3 4 5 6]\n",
        "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "[3]\n",
        "Score is  1.0\n"
       ]
      }
     ],
     "prompt_number": 80
    }
   ],
   "metadata": {}
  }
 ]
}